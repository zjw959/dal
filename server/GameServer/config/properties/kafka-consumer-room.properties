#内网统一使用 192.168.20.182
bootstrap.servers=192.168.20.182:9092
#bootstrap.servers=127.0.0.1:9092
#bootstrap.servers=192.168.10.15:9092
#consume分组。一条消息只会被同组的一个consume消费
group.id=test
#自动提交offset; false的话还需要手动调用consumer.commitSync()
enable.auto.commit=true
#自动提交offset的时间间隔   太短性能会差，太长如果crash重启后可能会重复消费的多(前提是消息在kafka服务器上还在)
auto.commit.interval.ms=1000
# 防止新的消费者分组不存在时，漏消费消息的情况发生。
# 原因：当创建一个新分组的消费者时，auto.offset.reset 值为 latest 时，表示消费最新的数据，即从 consumer 创建后生产的数据。这样会导致之前产生的数据不消费。
# 聊天会重复消费,因此设置为latest.
auto.offset.reset = latest
#session 过期时间 一旦心跳连接不上，超过这个时间就会链接断开
session.timeout.ms=30000
#session.timeout.ms=300000
#request.timeout.ms=400001
#group.min.session.timeout.ms=6000
#group.max.session.timeout.ms=320000
#一次拉取消息的最大数量
max.poll.records=500
#KEY的序列化方法
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#VALUE的序列化方法
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer